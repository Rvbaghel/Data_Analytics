{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846dc2b7",
   "metadata": {},
   "source": [
    "\n",
    "### You are given a dataset – “hotel_bookings.csv.” The dataset has a high number of null and  elements that need to be cleansed;  Your job is to create a separate DataFrame with only categorical columns and  perform the  following operations:\n",
    "### 1.\tFind the number of null values in each column of the new DataFrame\n",
    "### 2.\tReplace the null values with mode \n",
    "### 3.\tIn the \"hotel\" column, replace the hotel names with \"0\" and \"1\" based on the condition that – if, \"hotel\" = \"city_hotel\", then \"hotel\" = \"1\";  else, \"0\"\n",
    "### 4.\tUsing the label encoder, assign a unique country code to each country\n",
    "### 5.\tUsing onehot encoder, encode the “month” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "hotel_book= pd.read_csv('hotel_bookings.csv') \n",
    "hotel_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab67218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "hotel_book= pd.read_csv('hotel_bookings.csv') \n",
    "hotel_book\n",
    "\n",
    "hotel_book.head(5)\n",
    "hotel_book.tail(5)\n",
    "hotel_book.sample(5)\n",
    "hotel_book.describe()\n",
    "\n",
    "hotel_book.isnull()\n",
    "hotel_book.isnull().any()\n",
    "\n",
    "\n",
    "#Find the number of null values in each column of the new DataFrame\n",
    "hotel_book.isnull().sum()\n",
    "hotel_book=hotel_book.drop(['company','agent'],axis=1)\n",
    "hotel_book\n",
    "\n",
    "\n",
    "#Replace the null values with mode\n",
    "hotel_book=hotel_book.fillna(hotel_book['country'].value_counts().index[0])\n",
    "hotel_book\n",
    "hotel_book.isnull().sum()\n",
    "\n",
    "\n",
    "# In the \"hotel\" column, replace the hotel names with \"0\" and \"1\" based on the condition that \n",
    "# – if, \"hotel\" = \"city_hotel\", then \"hotel\" = \"1\"; else, \"0\"\n",
    "hotel_book['hotel']=np.where(hotel_book['hotel'].str.contains('City Hotel'),1,0)\n",
    "hotel_book\n",
    "hotel_book.sample(5)\n",
    "\n",
    "\n",
    "# Using the label encoder, assign a unique country code to each country\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE=LabelEncoder()\n",
    "hotel_book['country code']=LE.fit_transform(hotel_book['country'])\n",
    "hotel_book\n",
    "\n",
    "# OR\n",
    "\n",
    "LE=LabelEncoder()\n",
    "hotel_book['country']=LE.fit_transform(hotel_book['country'])\n",
    "hotel_book\n",
    "\n",
    "hotel_book.sample(5)\n",
    "\n",
    "\n",
    "# Using onehot encoder, encode the “month” column\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# OHE=OneHotEncoder()\n",
    "# hotel_book['month']=OHE.fit_transform(hotel_book['arrival_date_month'])\n",
    "# hotel_book\n",
    "\n",
    "# VALUE ERROR: Expected 2D array, got 1D array instead\n",
    "# SOLUTION: \n",
    "#OHE = OneHotEncoder(sparse=False, drop=None)\n",
    "#sparse=False: This ensures the output is a dense NumPy array, not a sparse matrix.\n",
    "             # It allows easy conversion into a Pandas DataFrame.\n",
    "# drop=None: This means no category will be dropped, so you'll get one column for each unique category in your input.\n",
    "             #Use drop='first' if you want to drop the first category to avoid multicollinearity in regression models.\n",
    "\n",
    "# Reshape to 2D array\n",
    "month_encoded = OHE.fit_transform(hotel_book[['arrival_date_month']])\n",
    "# Convert to DataFrame with appropriate column names\n",
    "month_df = pd.DataFrame(month_encoded, columns=OHE.get_feature_names_out(['arrival_date_month']))\n",
    "# Concatenate with original DataFrame\n",
    "hotel_book = pd.concat([hotel_book.drop('arrival_date_month', axis=1), month_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# USING RESHAPE\n",
    "# Convert column to NumPy array and reshape to 2D\n",
    "month_array = hotel_book['arrival_date_month'].to_numpy().reshape(-1, 1)\n",
    "# Fit and transform the reshaped array\n",
    "month_encoded = OHE.fit_transform(month_array)\n",
    "# Create DataFrame from encoded array\n",
    "month_df = pd.DataFrame(month_encoded, columns=OHE.get_feature_names_out(['arrival_date_month']))\n",
    "#Align indexes to avoid issues during concatenation\n",
    "month_df.index = hotel_book.index\n",
    "#Replace original column with new encoded columns\n",
    "hotel_book = pd.concat([hotel_book.drop('arrival_date_month', axis=1), month_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# USING get_dummies()\n",
    "\n",
    "hotel_book=pd.DataFrame(hotel_book)\n",
    "hotel_book\n",
    "hotel_book = pd.get_dummies(hotel_book, columns=['arrival_date_month'], prefix='month', drop_first=False)\n",
    "print(hotel_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee132f2",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbcd6a",
   "metadata": {},
   "source": [
    "### 1. Min-Max Scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16492f4d",
   "metadata": {},
   "source": [
    "#### USing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c66fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "# minmax = MinMaxScalar(feature_range=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column data\n",
    "x=hotel_book['lead_time']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba0f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " hotel_book['lead_time']= minmax.fit_transform(hotel_book[['lead_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c28988",
   "metadata": {},
   "source": [
    "#### Using Scrach [X= (X - X_min)/ (X_max - X_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e79f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lt=hotel_book['lead_time']\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book['lead_time']=(lt - lt.min()) / (lt.max() - lt.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book1 = hotel_book.copy()\n",
    "\n",
    "min_val = hotel_book['lead_time'].min()\n",
    "max_val = hotel_book['lead_time'].max()\n",
    "\n",
    "hotel_book1['lead_time'] = (hotel_book['lead_time'] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368764b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book1 = hotel_book.copy()\n",
    "\n",
    "x = ['lead_time']\n",
    "\n",
    "for col in x:\n",
    "    min_val = hotel_book[col].min()\n",
    "    max_val = hotel_book[col].max()\n",
    "    hotel_book1[col + '_scaled'] = (hotel_book[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(hotel_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e29312",
   "metadata": {},
   "source": [
    "### 2. Standard Scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c232129",
   "metadata": {},
   "source": [
    "#### using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss= StandardScaler()\n",
    "hotel_book['lead_time'] = ss.fit_transform(hotel_book[['lead_time']])\n",
    "print(hotel_book['lead_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8d730",
   "metadata": {},
   "source": [
    "#### using Scratch \n",
    "\n",
    "#### X = X - mean / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59012282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lt=hotel_book['lead_time']\n",
    "lt\n",
    "mean = lt.mean()\n",
    "std = lt.std()\n",
    "hotel_book['lead_time'] = (lt - mean) / std\n",
    "print(hotel_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c701f69",
   "metadata": {},
   "source": [
    "### 3. Robust Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657376a",
   "metadata": {},
   "source": [
    "#### Using Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2637399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robust = RobustScaler()\n",
    "hotel_book['lead_time'] = robust.fit_transform(hotel_book[['lead_time']])\n",
    "print(hotel_book['lead_time'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0945d0b",
   "metadata": {},
   "source": [
    "#### Using Scratch\n",
    "\n",
    "#### X = (X - median) / IQR\n",
    "\n",
    "#### IQR= Q_3 - Q_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=hotel_book['lead_time']\n",
    "lt\n",
    "\n",
    "q1 = lt.quantile(0.25)\n",
    "q3 = lt.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "median = lt.median()\n",
    "hotel_book['lead_time'] = (lt - median) / iqr\n",
    "print(hotel_book['lead_time'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d33d",
   "metadata": {},
   "source": [
    "### Normlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aece31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207946e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lt=hotel_book[['lead_time']].values\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b180d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm=normalize(lt)\n",
    "\n",
    "hotel_book['lead_time']=norm\n",
    "\n",
    "print(hotel_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e61d77",
   "metadata": {},
   "source": [
    "#### Normalization (specifically L2 normalization) scales the values so that the\n",
    "#### entire row (or feature vector) has a unit norm (length = 1)\n",
    "\n",
    "\n",
    "#### X_norm = X/sqrt(X^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5631d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book1 = hotel_book.copy()\n",
    "\n",
    "l2_norm = np.sqrt((hotel_book1['lead_time']**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_book1['lead_time'] = hotel_book1['lead_time'] / l2_norm\n",
    "print(hotel_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33e3a4",
   "metadata": {},
   "source": [
    "### You are given a dataset – “Heart_Disease.csv.” The dataset has a high number of null and elements that need to be cleansed;\n",
    "### 1. Find the number of null values in each column of the new DataFrame.\n",
    "### 2. Perform feature scaling on the numerical columns of the dataset using the following techniques:\n",
    "### (min max scalar, standard scalar, Robust Scalar)\n",
    "### 3. Use Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf33c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa4ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a520df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28dcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8887c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec64618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba35932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20783562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be808a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6506bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e1185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cc880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4fbeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c0d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b2287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5eca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348d4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cd9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b64bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719e942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb49769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee55b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b4fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
